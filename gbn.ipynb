{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gbn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_KyNiC5oYJ3eQNGgoAGAziGkJYo_WNCC",
      "authorship_tag": "ABX9TyPdztULf9r2a21eG7uMUwzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manishmcsa/Assigment-6/blob/main/gbn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fWbHpxOq7wW"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9GhiRodr6l4"
      },
      "source": [
        "class BatchNorm(nn.BatchNorm2d):\r\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True,\r\n",
        "                 bias=True):\r\n",
        "        super().__init__(num_features, eps=eps, momentum=momentum)\r\n",
        "        self.weight.data.fill_(1.0)\r\n",
        "        self.bias.data.fill_(0.0)\r\n",
        "        self.weight.requires_grad = weight\r\n",
        "        self.bias.requires_grad = bias\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwUALy9KsPy-"
      },
      "source": [
        "class GhostBatchNorm(BatchNorm):\r\n",
        "    def __init__(self, num_features, num_splits, **kw):\r\n",
        "        super().__init__(num_features, **kw)\r\n",
        "        self.num_splits = num_splits\r\n",
        "        self.running_mean = None\r\n",
        "        self.running_var = None\r\n",
        "        self.register_buffer('running_mean',\r\n",
        "                             torch.zeros(num_features * self.num_splits))\r\n",
        "        self.register_buffer('running_var',\r\n",
        "                             torch.ones(num_features * self.num_splits))\r\n",
        "\r\n",
        "    def train(self, mode=True):\r\n",
        "        if (self.training is True) and (\r\n",
        "                mode is False):  # lazily collate stats when we are going to\r\n",
        "            # use them\r\n",
        "            self.running_mean = torch.mean(\r\n",
        "                self.running_mean.view(self.num_splits, self.num_features),\r\n",
        "                dim=0).repeat(\r\n",
        "                self.num_splits)\r\n",
        "            self.running_var = torch.mean(\r\n",
        "                self.running_var.view(self.num_splits, self.num_features),\r\n",
        "                dim=0).repeat(\r\n",
        "                self.num_splits)\r\n",
        "        return super().train(mode)\r\n",
        "\r\n",
        "    def forward(self, inp):\r\n",
        "        N, C, H, W = inp.shape\r\n",
        "        if self.training or not self.track_running_stats:\r\n",
        "            return F.batch_norm(\r\n",
        "                inp.view(-1, C * self.num_splits, H, W), self.running_mean,\r\n",
        "                self.running_var,\r\n",
        "                self.weight.repeat(self.num_splits),\r\n",
        "                self.bias.repeat(self.num_splits),\r\n",
        "                True, self.momentum, self.eps).view(N, C, H, W)\r\n",
        "        else:\r\n",
        "            return F.batch_norm(\r\n",
        "                inp, self.running_mean[:self.num_features],\r\n",
        "                self.running_var[:self.num_features],\r\n",
        "                self.weight, self.bias, False, self.momentum, self.eps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}